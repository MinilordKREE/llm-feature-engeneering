{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.16) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: /data/chenxi/anaconda3/envs/myenv did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from prompt.response_prompt import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from transformers import BertModel, BertTokenizer\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = arff_to_dataframe(\"/data/chenxi/llm-feature-engeneering/dataset/diabetes.arff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models= {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(algorithm='ball_tree'),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Support Vector Machine': SVC(probability=True),  # Enable probability estimates\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = df.apply(lambda row: template.format(**row), axis=1)\n",
    "df['analysis']= prompts.apply(lambda x: decoder_for_gpt3(x, max_length = 1000))\n",
    "# Save the dataframe with the generated summaries to a new CSV file\n",
    "df['analysis'].to_csv('analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_sum = df['analysis'].apply(lambda row: template_for_sum.format(analysis=row))\n",
    "df['sum'] = prompts.apply(lambda x: decoder_for_gpt3(x, max_length = 1000))\n",
    "df['sum'].to_csv('sum.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "\n",
    "df['text_vector'] = df['response'].apply(lambda x: get_embedding(x, model='text-embedding-ada-002'))\n",
    "    \n",
    "def explode( col, prefix ):\n",
    "    n_cols = len( col[0] )\n",
    "    col_names = [ prefix + str(i) for i in range(n_cols) ]\n",
    "\n",
    "    return( pd.DataFrame( col.to_list(), columns=col_names) )\n",
    "\n",
    "tab_vec_name = 'text_vector'\n",
    "prefix = \"vec_\" \n",
    "\n",
    "# train_X\n",
    "exploded = explode( df[ tab_vec_name], prefix )\n",
    "df.loc[:, exploded.columns ] = exploded   # Idempotent replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              6      148             72             35        0  33.6   \n",
      "1              1       85             66             29        0  26.6   \n",
      "2              8      183             64              0        0  23.3   \n",
      "3              1       89             66             23       94  28.1   \n",
      "4              0      137             40             35      168  43.1   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "763           10      101             76             48      180  32.9   \n",
      "764            2      122             70             27        0  36.8   \n",
      "765            5      121             72             23      112  26.2   \n",
      "766            1      126             60              0        0  30.1   \n",
      "767            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                       0.627   50        1  \n",
      "1                       0.351   31        0  \n",
      "2                       0.672   32        1  \n",
      "3                       0.167   21        0  \n",
      "4                       2.288   33        1  \n",
      "..                        ...  ...      ...  \n",
      "763                     0.171   63        0  \n",
      "764                     0.340   27        0  \n",
      "765                     0.245   30        0  \n",
      "766                     0.349   47        1  \n",
      "767                     0.315   23        0  \n",
      "\n",
      "[768 rows x 9 columns]>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_models(df, models):\n",
    "\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    y = df['Outcome']\n",
    "\n",
    "    # Initialize multiple feature selection methods\n",
    "    feature_selection_methods = {\n",
    "        'SelectKBest': SelectKBest(mutual_info_classif, k='all'),\n",
    "    }\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Initialize an empty dictionary to store the selected features from each method\n",
    "    selected_features = {}\n",
    "\n",
    "    # Apply each feature selection method to the embeddings\n",
    "    for name, method in feature_selection_methods.items():\n",
    "        selected_features[name] = method.fit_transform(X_scaled, y)\n",
    "\n",
    "    # Train a model (for example, logistic regression) on the selected features and compute the performance\n",
    "    model = LogisticRegression()\n",
    "    scores = {}\n",
    "    for name, features in selected_features.items():\n",
    "        score = cross_val_score(model, features, y, cv=5, scoring='accuracy').mean()\n",
    "        scores[name] = score\n",
    "\n",
    "    # Determine the best feature selection method\n",
    "    best_method = max(scores, key=scores.get)\n",
    "\n",
    "    # Use the selected features from the best method for further analysis\n",
    "    X_selected = selected_features[best_method]\n",
    "\n",
    "    # Prepare cross-validationv\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize a dictionary to store the performance metrics for each model\n",
    "    performance_metrics = {\n",
    "        'accuracy': {model_name: [] for model_name in models.keys()},\n",
    "        'roc_auc': {model_name: [] for model_name in models.keys()},\n",
    "    }\n",
    "\n",
    "    # Train the models and compute the performance metrics\n",
    "    for name in models.keys():\n",
    "        model = models[name]\n",
    "        accuracy_scores = cross_val_score(model, X_selected, y, cv=kfold, scoring='accuracy')\n",
    "        roc_auc_scores = cross_val_score(model, X_selected, y, cv=kfold, scoring='roc_auc')\n",
    "        \n",
    "        # Store the scores in the performance metrics dictionary\n",
    "        performance_metrics['accuracy'][name] = accuracy_scores\n",
    "        performance_metrics['roc_auc'][name] = roc_auc_scores\n",
    "\n",
    "        # Print the mean and standard deviation of the scores\n",
    "        print(f'{name}:')\n",
    "        print(f'Accuracy: {accuracy_scores.mean()} ± {accuracy_scores.std()}')\n",
    "        print(f'ROC AUC: {roc_auc_scores.mean()} ± {roc_auc_scores.std()}')\n",
    "        print()\n",
    "\n",
    "    # Prepare colors\n",
    "    colors = ['black', 'green', 'blue', 'red']\n",
    "\n",
    "    for metric in ['accuracy', 'roc_auc']:\n",
    "        # Plot the performance metrics\n",
    "        plt.figure(figsize=(15, 10))\n",
    "\n",
    "        x_ticks_positions = np.arange(len(models))  # change here\n",
    "        data_to_plot = [performance_metrics[metric][model_name] for model_name in models.keys()]\n",
    "        boxplot = plt.boxplot(data_to_plot, positions=x_ticks_positions, widths=0.6, patch_artist=True,\n",
    "                            boxprops=dict(facecolor=colors[0], color=colors[0], alpha=0.6),\n",
    "                            capprops=dict(color=colors[0]),\n",
    "                            whiskerprops=dict(color=colors[0]),\n",
    "                            flierprops=dict(color=colors[0], markeredgecolor=colors[0]),\n",
    "                            medianprops=dict(color='black'))\n",
    "\n",
    "        plt.title(f\"Model performance ({metric})\")\n",
    "        plt.ylabel(metric)\n",
    "        plt.xticks(ticks=x_ticks_positions, labels=models.keys())  # change here\n",
    "        plt.show()\n",
    "\n",
    "evaluate_models(df, models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
