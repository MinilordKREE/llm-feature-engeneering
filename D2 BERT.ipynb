{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:base:Downloading pre-trained model 'distilbert-base-uncased'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: /data/chenxi/anaconda3/envs/myenv did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmp2muwa3_m\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmp2muwa3_m/_remote_module_non_scriptable.py\n",
      "INFO:base:Downloading tokenizer for 'distilbert-base-uncased'\n"
     ]
    }
   ],
   "source": [
    "generator = EmbeddingGeneratorForNLPSequenceClassification.from_use_case(\n",
    "    use_case=\"NLP.SequenceClassification\",\n",
    "    model_name=\"distilbert-base-uncased\",\n",
    "    tokenizer_max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming your data is stored in a csv file named 'data.csv'\n",
    "df = pd.read_csv(r'/data/chenxi/3/training_data.csv')\n",
    "df=df.drop(columns=['Patient ID','Recording locations:','Additional ID'])\n",
    "df_clean = df.copy()\n",
    "df['Murmur locations'] = df['Murmur locations'].str.split('+')\n",
    "locations = ['PV', 'TV', 'AV', 'MV']\n",
    "for location in locations:\n",
    "    df[location] = df['Murmur locations'].apply(lambda x: 1 if x is not np.nan and location in x else 0)\n",
    "df.drop('Murmur locations', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Map the Age feature\n",
    "age_mapping = {'Neonate': 1, 'Infant': 2, 'Child': 3, 'Adolescent': 4, 'Young adult': 5}\n",
    "df_clean['Age'] = df_clean['Age'].map(age_mapping)\n",
    "df_clean['Age'].fillna(-1, inplace=True)\n",
    "\n",
    "# 2. Map the Sex feature\n",
    "le = LabelEncoder()\n",
    "df_clean['Sex'] = le.fit_transform(df_clean['Sex'])\n",
    "\n",
    "# 3. Map the Pregnancy status feature\n",
    "df_clean['Pregnancy status'] = df_clean['Pregnancy status'].map({False: 0, True: 1})\n",
    "\n",
    "# 4. Handle missing values in Height and Weight\n",
    "df_clean['Height'].fillna((df_clean['Height'].mean()), inplace=True)\n",
    "df_clean['Weight'].fillna((df_clean['Weight'].mean()), inplace=True)\n",
    "\n",
    "# 5. Map the Murmur feature\n",
    "df_clean['Murmur'] = df_clean['Murmur'].map({'Present': 1, 'Absent': 0, 'Unknown': 2})\n",
    "\n",
    "# 6. Handle the 'Murmur locations' feature\n",
    "df_clean['Murmur locations'] = df_clean['Murmur locations'].str.split('+')\n",
    "locations = ['PV', 'TV', 'AV', 'MV']\n",
    "for location in locations:\n",
    "    df_clean[location] = df_clean['Murmur locations'].apply(lambda x: 1 if x is not np.nan and location in x else 0)\n",
    "df_clean.drop('Murmur locations', axis=1, inplace=True)\n",
    "\n",
    "# 7. Map the 'Most audible location' feature\n",
    "df_clean['Most audible location'] = df_clean['Most audible location'].map({np.nan: 0, 'PV': 1, 'TV': 2, 'AV': 3, 'MV': 4})\n",
    "\n",
    "# 8. Map the Outcome feature\n",
    "df_clean['Outcome'] = df_clean['Outcome'].map({'Normal': 0, 'Abnormal': 1})\n",
    "\n",
    "# 9. Map the Campaign feature\n",
    "df_clean['Campaign'] = df_clean['Campaign'].map({'CC2014': 0, 'CC2015': 1})\n",
    "\n",
    "# 10. Map other string features\n",
    "string_features = ['Systolic murmur timing', 'Systolic murmur shape', 'Systolic murmur grading', 'Systolic murmur pitch', 'Systolic murmur quality', \n",
    "                   'Diastolic murmur timing', 'Diastolic murmur shape', 'Diastolic murmur grading', 'Diastolic murmur pitch', 'Diastolic murmur quality']\n",
    "for feature in string_features:\n",
    "    df_clean[feature] = df_clean[feature].astype('category')\n",
    "    df_clean[feature] = df_clean[feature].cat.codes\n",
    "    df_clean[feature].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Support Vector Machine': SVC(probability=True),  # Enable probability estimates\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "def get_matching_cols(df, regex):\n",
    "    r = re.compile(regex)\n",
    "    return( list( filter( r.match, df.columns) ) )\n",
    "\n",
    "def get_embedding_cols(df):\n",
    "    return get_matching_cols(df, \"(vec_\\d+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:base:Generating embedding vectors\n",
      "Map: 100%|██████████| 942/942 [00:03<00:00, 235.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Sex  Height  Weight  Pregnancy status  Murmur  Most audible location  \\\n",
      "0  3.0    0    98.0    15.9                 0       0                      0   \n",
      "1  3.0    0   103.0    13.1                 0       1                      2   \n",
      "2  3.0    1   115.0    19.1                 0       2                      0   \n",
      "3  3.0    1    98.0    15.9                 0       1                      2   \n",
      "4  3.0    1    87.0    11.2                 0       1                      1   \n",
      "\n",
      "   Systolic murmur timing  Systolic murmur shape  Systolic murmur grading  \\\n",
      "0                      -1                     -1                       -1   \n",
      "1                       1                      2                        2   \n",
      "2                      -1                     -1                       -1   \n",
      "3                       1                      3                        0   \n",
      "4                       0                      3                        1   \n",
      "\n",
      "   ...  Diastolic murmur pitch  Diastolic murmur quality  Outcome  Campaign  \\\n",
      "0  ...                      -1                        -1        1         1   \n",
      "1  ...                      -1                        -1        1         1   \n",
      "2  ...                      -1                        -1        1         1   \n",
      "3  ...                      -1                        -1        1         1   \n",
      "4  ...                      -1                        -1        1         1   \n",
      "\n",
      "   PV  TV  AV  MV                                                sum  \\\n",
      "0   0   0   0   0  Based on the analysis of the hypothetical pati...   \n",
      "1   1   1   1   1  In summary, the common patterns, findings, or ...   \n",
      "2   0   0   0   0  In summary, the common patterns, findings, or ...   \n",
      "3   0   1   0   0  In summary, the common patterns, findings, or ...   \n",
      "4   1   1   1   1  In summary, the common patterns, findings, or ...   \n",
      "\n",
      "                                         text_vector  \n",
      "0  [-0.30945485830307007, -0.24493613839149475, -...  \n",
      "1  [-0.33756694197654724, -0.15302056074142456, 0...  \n",
      "2  [-0.21484524011611938, -0.23496302962303162, -...  \n",
      "3  [-0.3927968740463257, -0.20479831099510193, 0....  \n",
      "4  [-0.381816565990448, -0.13195589184761047, -0....  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: accuracy: 0.6571372284138242 ± 0.024904741438151398\n",
      "K-Nearest Neighbors: accuracy: 0.6454801305865135 ± 0.023120653870363102\n",
      "Naive Bayes: accuracy: 0.6211021051446584 ± 0.03884666434780703\n",
      "Decision Tree: accuracy: 0.5870595519531691 ± 0.03268688101409344\n",
      "Random Forest: accuracy: 0.6379882922436113 ± 0.023101849605705275\n",
      "AdaBoost: accuracy: 0.6210401891252955 ± 0.03301214500072233\n",
      "Gradient Boosting: accuracy: 0.6390746369469774 ± 0.0388952165189523\n",
      "Support Vector Machine: accuracy: 0.6645840369244624 ± 0.024860943477738248\n",
      "XGBoost: accuracy: 0.602910052910053 ± 0.025908799449801546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 199\u001b[0m\n\u001b[1;32m    195\u001b[0m         plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m    198\u001b[0m methods \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mbaseline\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSelectK\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPCA\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 199\u001b[0m evaluate_models(df_clean, models, methods)\n",
      "Cell \u001b[0;32mIn[7], line 178\u001b[0m, in \u001b[0;36mevaluate_models\u001b[0;34m(df, models, methods)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39m# ... (rest of the evaluation function logic)\u001b[39;00m\n\u001b[1;32m    177\u001b[0m kfold \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m performance_metrics \u001b[39m=\u001b[39m {metric: {model_name: cross_val_score(model, X_final, y, cv\u001b[39m=\u001b[39mkfold, scoring\u001b[39m=\u001b[39mmetric) \u001b[39mfor\u001b[39;00m model_name, model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mitems()}}\n\u001b[1;32m    180\u001b[0m \u001b[39mfor\u001b[39;00m name, scores \u001b[39min\u001b[39;00m performance_metrics[metric]\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    181\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mmetric\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mscores\u001b[39m.\u001b[39mmean()\u001b[39m}\u001b[39;00m\u001b[39m ± \u001b[39m\u001b[39m{\u001b[39;00mscores\u001b[39m.\u001b[39mstd()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 178\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39m# ... (rest of the evaluation function logic)\u001b[39;00m\n\u001b[1;32m    177\u001b[0m kfold \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m performance_metrics \u001b[39m=\u001b[39m {metric: {model_name: cross_val_score(model, X_final, y, cv\u001b[39m=\u001b[39;49mkfold, scoring\u001b[39m=\u001b[39;49mmetric) \u001b[39mfor\u001b[39;00m model_name, model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mitems()}}\n\u001b[1;32m    180\u001b[0m \u001b[39mfor\u001b[39;00m name, scores \u001b[39min\u001b[39;00m performance_metrics[metric]\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    181\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mmetric\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mscores\u001b[39m.\u001b[39mmean()\u001b[39m}\u001b[39;00m\u001b[39m ± \u001b[39m\u001b[39m{\u001b[39;00mscores\u001b[39m.\u001b[39mstd()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:509\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    507\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 509\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    510\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    511\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    512\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    513\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    514\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    515\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    516\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    517\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    518\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    519\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    520\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    521\u001b[0m )\n\u001b[1;32m    522\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 267\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    268\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    269\u001b[0m         clone(estimator),\n\u001b[1;32m    270\u001b[0m         X,\n\u001b[1;32m    271\u001b[0m         y,\n\u001b[1;32m    272\u001b[0m         scorers,\n\u001b[1;32m    273\u001b[0m         train,\n\u001b[1;32m    274\u001b[0m         test,\n\u001b[1;32m    275\u001b[0m         verbose,\n\u001b[1;32m    276\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    277\u001b[0m         fit_params,\n\u001b[1;32m    278\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    279\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    280\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    281\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    284\u001b[0m )\n\u001b[1;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[1;32m    288\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    682\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[1;32m   1493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMcAAAMtCAYAAACb6xY9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABRz0lEQVR4nO3df3RdZZ3o/0+a9EeO4QQjaZuWQnByaaqUHw1QQ0XgWoerdMbq1VVHOlRUvBdbKdRxaO0V/EWrothe4VJhWeGuyoBTARnAorfeIkoYMMhMcZqWDpRytSnpqvSQJrSQnO8fLsM306TkxKb58bxea2V1de/n2fs5K9tj82afnaJ8Pp8PAAAAAEjQqMFeAAAAAAAMFnEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECySgZ7AUdKZ2dn/P73v49jjjkmioqKBns5AAAAAAySfD4fL7/8ckyaNClGjTr8vWEjJo79/ve/jylTpgz2MgAAAAAYIl544YU4/vjjDztmxMSxY445JiL++KKz2ewgrwYAAACAwZLL5WLKlCldvehwRkwc+9NHKbPZrDgGAAAAQJ8eveWB/AAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJKhnsBQAAAABHRkdHRzzyyCOxa9euqKqqinPPPTeKi4sHe1kwpLlzDAAAAEaAu+++O2pqauKCCy6Ij370o3HBBRdETU1N3H333YO9NBjSxDEAAAAY5u6+++740Ic+FNOnT4+GhoZ4+eWXo6GhIaZPnx4f+tCHBDI4jKJ8Pp8f7EUcCblcLsrLy2Pfvn2RzWYHezkAAABwVHR0dERNTU1Mnz497r333hg16vX7YDo7O2Pu3Lnx9NNPxzPPPOMjliSjkE7kzjEAAAAYxh555JHYsWNHfP7zn+8WxiIiRo0aFcuWLYvnnnsuHnnkkUFaIQxt4hgAAAAMY7t27YqIiFNOOaXH/X/a/qdxQHfiGAAAAAxjVVVVERHx9NNP97j/T9v/NA7oThwDAACAYezcc8+N6urqWLFiRXR2dnbb19nZGStXroyTTjopzj333EFaIQxt4hgAAAAMY8XFxfGtb30r7r///pg7d26331Y5d+7cuP/+++Ob3/ymh/FDL0oGewEAAADAn+eDH/xgrF+/Pj772c/GOeec07X9pJNOivXr18cHP/jBQVwdDG1F+Xw+P9iLOBIK+RWdAAAAMBJ1dHTEI488Ert27Yqqqqo499xz3TFGkgrpRP36WOVNN90U1dXVMW7cuJg5c2Y8/vjjvY49//zzo6io6JCviy66qGtMPp+Pa665JqqqqqK0tDRmz54dzzzzTH+WBgAAAMkqLi6O888/P/7mb/4mzj//fGEM+qDgOHbXXXfFkiVL4tprr40nn3wyTjvttLjwwgvjxRdf7HH83XffHbt27er6evrpp6O4uDg+/OEPd435xje+Ef/zf/7PWLNmTfzzP/9zvOlNb4oLL7wwXnnllf6/MgAAAAB4AwV/rHLmzJlx1llnxY033hgRf/zNF1OmTInPfOYzsXTp0jecv2rVqrjmmmti165d8aY3vSny+XxMmjQpPvvZz8bf/d3fRUTEvn37YsKECXHbbbfFRz7ykT6ty8cqAQAAAIgYwI9VHjx4MBobG2P27NmvH2DUqJg9e3Y0NDT06Rjf+9734iMf+Ui86U1vioiI5557Lpqbm7sds7y8PGbOnHnYYx44cCByuVy3LwAAAAAoREFxbM+ePdHR0RETJkzotn3ChAnR3Nz8hvMff/zxePrpp+OTn/xk17Y/zSv0mCtXrozy8vKurylTphTyUgAAAACgfw/k76/vfe97MX369Dj77LP/7GMtW7Ys9u3b1/X1wgsvHIEVAgAAAJCSguLYcccdF8XFxbF79+5u23fv3h0TJ0487Nz9+/fHnXfeGZ/4xCe6bf/TvEKPOXbs2Mhms92+AAAAAKAQBcWxMWPGRF1dXWzcuLFrW2dnZ2zcuDHq6+sPO/cf//Ef48CBAzF//vxu20866aSYOHFit2Pmcrn453/+5zc8JgAAAAD8OUoKnbBkyZJYsGBBnHnmmXH22WfHqlWrYv/+/XHppZdGRMQll1wSkydPjpUrV3ab973vfS/mzp0bb3nLW7ptLyoqiiuvvDK++tWvxn/6T/8pTjrppPjCF74QkyZNirlz5/b/lQEAAADAGyg4js2bNy9aWlrimmuuiebm5jj99NNjw4YNXQ/U37lzZ4wa1f2GtK1bt8Yvf/nL+OlPf9rjMf/+7/8+9u/fH5/61KfipZdeine+852xYcOGGDduXD9eEgAAAAD0TVE+n88P9iKOhFwuF+Xl5bFv3z7PHwMAAABIWCGd6Kj+tkoAAAAAGErEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAySoZ7AVQmLa2tmhqajpke3t7e+zYsSOqq6ujtLS0x7m1tbWRyWQGeokAAMBR4GcDgCNDHBtmmpqaoq6url9zGxsbY8aMGUd4RQAAwGDwswHAkSGODTO1tbXR2Nh4yPYtW7bE/PnzY926dTFt2rRe5wIAACODnw0AjgxxbJjJZDKH/S8806ZN81+AAAAgAX42ADgyPJAfAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAySoZ7AUAUJi2trZoamrqcV97e3vs2LEjqquro7S09JD9tbW1kclkBnqJAAAAw0a/4thNN90U119/fTQ3N8dpp50W3/nOd+Lss8/udfxLL70Uy5cvj7vvvjv27t0bJ554YqxatSre9773RURER0dHfPGLX4x169ZFc3NzTJo0KT72sY/F//gf/yOKior698oARqimpqaoq6vr19zGxsaYMWPGEV4RAADA8FVwHLvrrrtiyZIlsWbNmpg5c2asWrUqLrzwwti6dWuMHz/+kPEHDx6M97znPTF+/PhYv359TJ48OZ5//vk49thju8Z8/etfj5tvvjluv/32ePvb3x6//vWv49JLL43y8vK44oor/qwXCDDS1NbWRmNjY4/7tmzZEvPnz49169bFtGnTepwLAADA6wqOYzfccENcdtllcemll0ZExJo1a+KBBx6ItWvXxtKlSw8Zv3bt2ti7d288+uijMXr06IiIqK6u7jbm0Ucfjfe///1x0UUXde3/h3/4h3j88ccLXR7AiJfJZN7w7q9p06a5QwwAAKAPCnog/8GDB6OxsTFmz579+gFGjYrZs2dHQ0NDj3Puu+++qK+vj4ULF8aECRPilFNOiRUrVkRHR0fXmHPOOSc2btwY27Zti4iIf/mXf4lf/vKX8d73vrfXtRw4cCByuVy3LwAAAAAoREF3ju3Zsyc6OjpiwoQJ3bZPmDCh14dDP/vss/Hzn/88Lr744njwwQdj+/bt8elPfzpeffXVuPbaayMiYunSpZHL5aK2tjaKi4ujo6Mjrrvuurj44ot7XcvKlSvjS1/6UiHLBwAAAIBuCrpzrD86Oztj/Pjxccstt0RdXV3Mmzcvli9fHmvWrOka88Mf/jB+8IMfxB133BFPPvlk3H777fHNb34zbr/99l6Pu2zZsti3b1/X1wsvvDDQLwUAAACAEaagO8eOO+64KC4ujt27d3fbvnv37pg4cWKPc6qqqmL06NFRXFzctW3atGnR3NwcBw8ejDFjxsTnPve5WLp0aXzkIx+JiIjp06fH888/HytXrowFCxb0eNyxY8fG2LFjC1k+AAAAAHRT0J1jY8aMibq6uti4cWPXts7Ozti4cWPU19f3OGfWrFmxffv26Ozs7Nq2bdu2qKqqijFjxkRERFtbW4wa1X0pxcXF3eYAAAAAwJFW8McqlyxZErfeemvcfvvtsWXLlrj88stj//79Xb+98pJLLolly5Z1jb/88stj7969sXjx4ti2bVs88MADsWLFili4cGHXmL/6q7+K6667Lh544IHYsWNH3HPPPXHDDTfEBz7wgSPwEgEAAACgZwV9rDIiYt68edHS0hLXXHNNNDc3x+mnnx4bNmzoekj/zp07u90FNmXKlHjooYfiqquuilNPPTUmT54cixcvjquvvrprzHe+8534whe+EJ/+9KfjxRdfjEmTJsV/+2//La655poj8BIBAAAAoGcFx7GIiEWLFsWiRYt63Ldp06ZDttXX18djjz3W6/GOOeaYWLVqVaxatao/ywEAAACAfhnw31YJAAAAAEOVOAYAAABAssQxAAAAAJIljgEAAACQrH49kB8AAICjY+/evdHa2trn8bt27er6c+fOnX2eV1ZWFhUVFQWvD2C4E8cAAACGqL1798bixYujpaWlz3NyuVxERFx33XWRzWb7PK+ysjJWr14tkAHJEccAAACGqNbW1mhpaYnS0tLIZDJ9mlNeXh7l5eWRzWajpKRvP/K1tbVFS0tLtLa2imNAcsQxAACAIS6TyURZWVmfxx977LEFn6O9vb3gOQAjgQfyAwAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWSWDvQB6tnfv3mhtbe3z+F27dnX9uXPnzj7PKysri4qKioLXx8Dr7Rpob2+P7du39+uYNTU1UVpa2m2bawAAAIY2PxvAwBLHhqC9e/fG4sWLo6Wlpc9zcrlcRERcd911kc1m+zyvsrIyVq9e7Q1wiDncNZDL5aKhoaFfx62vrz/k+nANAADA0OVnAxh44tgQ1NraGi0tLVFaWhqZTKZPc8rLy6O8vDyy2WyUlPTt29rW1hYtLS3R2trqzW+IOdw18KfvdX/8x+vDNQAAAEObnw1g4IljQ1gmk4mysrI+jz/22GMLPkd7e3vBczh6ersG+vO97o1rAAAAhj4/G8DA8UB+AAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACSrZLAXwKHa29sjl8tFUVFRvPLKKwN2nra2tsjlctHe3j5g5wAAjry2trZoamrqcV97e3vs2LEjqquro7S09JD9tbW1kclkBnqJABwhfj6EgSeODUHbt2+PhoaGo3q+qVOnHrXzAQB/nqampqirq+vX3MbGxpgxY8YRXhEAA8XPhzDwxLEhqKamJurr66O8vHxA/8tuW1tb7Nu3L2pqagbsHADAkVdbWxuNjY097tuyZUvMnz8/1q1bF9OmTetxLgDDh58PYeCJY0NQaWlpZLPZqKioiLKysgE7T2tra+Tz+R4/cgEADF2ZTOYN7/6aNm2aO8QARgA/H8LA80B+AAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAsvoVx2666aaorq6OcePGxcyZM+Pxxx8/7PiXXnopFi5cGFVVVTF27Ng4+eST48EHH+w25ne/+13Mnz8/3vKWt0RpaWlMnz49fv3rX/dneQAAAADQJyWFTrjrrrtiyZIlsWbNmpg5c2asWrUqLrzwwti6dWuMHz/+kPEHDx6M97znPTF+/PhYv359TJ48OZ5//vk49thju8b84Q9/iFmzZsUFF1wQP/nJT6KysjKeeeaZePOb3/xnvTgAAAAAOJyC49gNN9wQl112WVx66aUREbFmzZp44IEHYu3atbF06dJDxq9duzb27t0bjz76aIwePToiIqqrq7uN+frXvx5TpkyJ73//+13bTjrppMOu48CBA3HgwIGuv+dyuUJfCgAAAACJK+hjlQcPHozGxsaYPXv26wcYNSpmz54dDQ0NPc657777or6+PhYuXBgTJkyIU045JVasWBEdHR3dxpx55pnx4Q9/OMaPHx9nnHFG3HrrrYddy8qVK6O8vLzra8qUKYW8FAAAAAAo7M6xPXv2REdHR0yYMKHb9gkTJkRTU1OPc5599tn4+c9/HhdffHE8+OCDsX379vj0pz8dr776alx77bVdY26++eZYsmRJfP7zn48nnngirrjiihgzZkwsWLCgx+MuW7YslixZ0vX3XC4nkAEAADAitbW1HbLttdde6/enqLLZbJSUvJ4Eejo+pKLgj1UWqrOzM8aPHx+33HJLFBcXR11dXfzud7+L66+/viuOdXZ2xplnnhkrVqyIiIgzzjgjnn766VizZk2vcWzs2LExduzYgV4+AAAADJqysrKorKyMlpaWaG9v77Yvl8v1+imuN1JfXx/ZbLbbtsrKyigrK+v3WmG4KiiOHXfccVFcXBy7d+/utn337t0xceLEHudUVVXF6NGjo7i4uGvbtGnTorm5OQ4ePBhjxoyJqqqqeNvb3tZt3rRp0+JHP/pRIcsDAACAEaWioiJWr14dra2th+xrb2+P7du39+u4NTU1UVpa2m1bWVlZVFRU9Ot4MJwVFMfGjBkTdXV1sXHjxpg7d25E/PGur40bN8aiRYt6nDNr1qy44447orOzM0aN+uMjzrZt2xZVVVUxZsyYrjFbt27tNm/btm1x4oknFvp6AAAAYESpqKjoNVpNnTr1KK8GRp6CHsgfEbFkyZK49dZb4/bbb48tW7bE5ZdfHvv37+/67ZWXXHJJLFu2rGv85ZdfHnv37o3FixfHtm3b4oEHHogVK1bEwoULu8ZcddVV8dhjj8WKFSti+/btcccdd8Qtt9zSbQwAAAAAHGkFP3Ns3rx50dLSEtdcc000NzfH6aefHhs2bOh6SP/OnTu77hCLiJgyZUo89NBDcdVVV8Wpp54akydPjsWLF8fVV1/dNeass86Ke+65J5YtWxZf/vKX46STTopVq1bFxRdffAReIgAAAAD0rF8P5F+0aFGvH6PctGnTIdvq6+vjscceO+wx58yZE3PmzOnPcgAAAACgXwr+WCUAAAAAjBTiGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWSWDvQAAAKBwbW1t0dTUdMj29vb22LFjR1RXV0dpaekh+2trayOTyRyNJQLAsCCOAQDAMNTU1BR1dXUFz2tsbIwZM2YMwIoAYHgSxwAAYBiqra2NxsbGQ7Zv2bIl5s+fH+vWrYtp06b1OA8AeJ04BgAAw1AmkznsHWDTpk1zhxgA9IEH8gMAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJ8tsqAQCGsL1790Zra2ufx+/atavrz507d/Z5XllZWVRUVBS8PgaeawAABpY4BgAwRO3duzcWL14cLS0tfZ6Ty+UiIuK6666LbDbb53mVlZWxevVqcWSIcQ0AwMATxwAAhqjW1tZoaWmJ0tLSyGQyfZpTXl4e5eXlkc1mo6Skb//Ua2tri5aWlmhtbRVGhhjXAAAMPHEMAGCIy2QyUVZW1ufxxx57bMHnaG9vL3gOR49rAAAGjgfyAwAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFklg70AAHq3d+/eaG1t7fP4Xbt2df25c+fOPs0pKyuLioqKfq0PAABguBPHAIaovXv3xuLFi6OlpaXPc3K5XEREXHfddZHNZvs0p7KyMlavXi2QAQAASRLHAIao1tbWaGlpidLS0shkMn2aU15eHuXl5ZHNZqOk5I3f4tva2qKlpSVaW1vFMQAAIEniGMAQl8lkoqysrM/jjz322IKO397eXuCKAAAARg4P5AcAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEhWyWAvAAAAAIDCtbW1RVNTU4/72tvbY8eOHVFdXR2lpaWH7K+trY1MJjPQSxwWxDEAAACAYaipqSnq6ur6NbexsTFmzJhxhFc0PIljAAAAAMNQbW1tNDY29rhvy5YtMX/+/Fi3bl1Mmzatx7n8kTgGAAAAMAxlMpk3vPtr2rRp7hB7Ax7IDwAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACTLb6sEgGGmra0tmpqaetzX3t4eO3bsiOrq6igtLT1kf21tbWQymYFeIkdIe3t75HK5KCoqildeeWXAztPW1ha5XC7a29sH7BwAAEOVOAYAw0xTU1PU1dX1a25jY6Nf5T2MbN++PRoaGo7q+aZOnXrUzgcAMBSIYwAwzNTW1kZjY2OP+7Zs2RLz58+PdevWxbRp03qcy/BRU1MT9fX1UV5ePqB3/LW1tcW+ffuipqZmwM4BADBUiWMAMMxkMpk3vPtr2rRp7hAbAUpLSyObzUZFRUWUlZUN2HlaW1sjn8/3+FFcAICRzgP5AQAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASFa/4thNN90U1dXVMW7cuJg5c2Y8/vjjhx3/0ksvxcKFC6OqqirGjh0bJ598cjz44IM9jv3a174WRUVFceWVV/ZnaQAAAADQZyWFTrjrrrtiyZIlsWbNmpg5c2asWrUqLrzwwti6dWuMHz/+kPEHDx6M97znPTF+/PhYv359TJ48OZ5//vk49thjDxn7xBNPxHe/+9049dRT+/ViAAAAAKAQBcexG264IS677LK49NJLIyJizZo18cADD8TatWtj6dKlh4xfu3Zt7N27Nx599NEYPXp0RERUV1cfMq61tTUuvvjiuPXWW+OrX/1qocuCEaW9vT1yuVwUFRXFK6+8MmDnaWtri1wuF+3t7QN2DgAAABjKCopjBw8ejMbGxli2bFnXtlGjRsXs2bOjoaGhxzn33Xdf1NfXx8KFC+PHP/5xVFZWxkc/+tG4+uqro7i4uGvcwoUL46KLLorZs2f3KY4dOHAgDhw40PX3XC5XyEuBIW379u29/m9qoM43derUo3Y+AAAAGCoKimN79uyJjo6OmDBhQrftEyZMiKamph7nPPvss/Hzn/88Lr744njwwQdj+/bt8elPfzpeffXVuPbaayMi4s4774wnn3wynnjiiT6vZeXKlfGlL32pkOXDsFFTUxP19fVRXl4emUxmwM7T1tYW+/bti5qamgE7BwAAAAxlBX+sslCdnZ0xfvz4uOWWW6K4uDjq6urid7/7XVx//fVx7bXXxgsvvBCLFy+On/3sZzFu3Lg+H3fZsmWxZMmSrr/ncrmYMmXKQLwEOOpKS0sjm81GRUVFlJWVDdh5WltbI5/PR2lp6YCdAwAAAIayguLYcccdF8XFxbF79+5u23fv3h0TJ07scU5VVVWMHj2620cop02bFs3NzV0f03zxxRdjxowZXfs7OjriF7/4Rdx4441x4MCBbnP/ZOzYsTF27NhClg8AAAAA3YwqZPCYMWOirq4uNm7c2LWts7MzNm7cGPX19T3OmTVrVmzfvj06Ozu7tm3bti2qqqpizJgx8e53vzs2b94cTz31VNfXmWeeGRdffHE89dRTPYYxAAAAADgSCv5Y5ZIlS2LBggVx5plnxtlnnx2rVq2K/fv3d/32yksuuSQmT54cK1eujIiIyy+/PG688cZYvHhxfOYzn4lnnnkmVqxYEVdccUVERBxzzDFxyimndDvHm970pnjLW95yyHYAAAAAOJIKjmPz5s2LlpaWuOaaa6K5uTlOP/302LBhQ9dD+nfu3BmjRr1+Q9qUKVPioYceiquuuipOPfXUmDx5cixevDiuvvrqI/cqAAAAAKAf+vVA/kWLFsWiRYt63Ldp06ZDttXX18djjz3W5+P3dAwAAAAAONIG/LdVAv3X1tbW57GvvfZa5HK5yGazUVLSt/9pF3J8AAAAGInEMRiCysrKorKyMlpaWqK9vb1Pc3K5XDQ0NER9fX1ks9k+n6uysjLKysr6u1QAAAAY1sQxGIIqKipi9erV0dra2uc5mzdvjjlz5sTy5ctj+vTpfZ5XVlYWFRUV/VkmAAAADHviGAxRFRUVBUWrPXv2REREVVVVnHDCCQO1LAAAABhRRr3xEAAAAAAYmcQxAAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBklQz2AuhdW1tbn8e+9tprkcvlIpvNRklJ376thRwfAAAAYCQSx4agsrKyqKysjJaWlmhvb+/TnFwuFw0NDVFfXx/ZbLbP56qsrIyysrL+LhUAAABgWBPHhqCKiopYvXp1tLa29nnO5s2bY86cObF8+fKYPn16n+eVlZVFRUVFf5YJAAAAMOyJY0NURUVFQdFqz549ERFRVVUVJ5xwwkAtCwAAAGBE8UB+AAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJKtksBcAAABAz9rb2yOXy0VRUVG88sorA3aetra2yOVy0d7ePmDnABiqxDEAAIAhavv27dHQ0HBUzzd16tSjdj6AoUAcAwAAGKJqamqivr4+ysvLI5PJDNh52traYt++fVFTUzNg5wAYqsQxAACAIaq0tDSy2WxUVFREWVnZgJ2ntbU18vl8lJaWDtg5AIYqD+QHAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZJUM9gIAAACAI6OjoyMeeeSR2LVrV1RVVcW5554bxcXFg70sGNLcOQYAAAAjwN133x01NTVxwQUXxEc/+tG44IILoqamJu6+++7BXhoMaeIYAAAADHN33313fOhDH4rp06dHQ0NDvPzyy9HQ0BDTp0+PD33oQwIZHIY4BgAAAMNYR0dHfPazn405c+bEvffeG+94xzuirKws3vGOd8S9994bc+bMib/7u7+Ljo6OwV4qDEmeOTbMtLW1RVNT0yHbt2zZ0u3PntTW1kYmkxmwtQEAA6Otra3PY1977bXI5XKRzWajpKRv/9Qr5PgADD2PPPJI7NixI/7hH/4hRo3qfg/MqFGjYtmyZXHOOefEI488Eueff/7gLBKGMHFsmGlqaoq6urpe98+fP7/XfY2NjTFjxoyBWBYAMADKysqisrIyWlpaor29vU9zcrlcNDQ0RH19fWSz2T6fq7KyMsrKyvq7VAAG0a5duyIi4pRTTulx/5+2/2kc0J04NszU1tZGY2PjIdvb29tjx44dUV1dHaWlpb3OBQCGj4qKili9enW0trb2ec7mzZtjzpw5sXz58pg+fXqf55WVlUVFRUV/lgnAIKuqqoqIiKeffjre8Y53HLL/6aef7jYO6E4cG2YymUyvd3/NmjXrKK8GABhoFRUVBUWrPXv2RMQffwA64YQTBmpZAAwh5557blRXV8eKFSvi3nvv7fbRys7Ozli5cmWcdNJJce655w7iKmHo8kB+AAAAGMaKi4vjW9/6Vtx///0xd+7cbr+tcu7cuXH//ffHN7/5zSguLh7spcKQ5M4xAAAAGOY++MEPxvr16+Ozn/1snHPOOV3bTzrppFi/fn188IMfHMTVwdAmjgEAAMAI8MEPfjDe//73xyOPPBK7du2KqqqqOPfcc90xBm9AHAMAAIARori4OM4///zBXgYMK545BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLL6FcduuummqK6ujnHjxsXMmTPj8ccfP+z4l156KRYuXBhVVVUxduzYOPnkk+PBBx/s2r9y5co466yz4phjjonx48fH3LlzY+vWrf1ZGgAAAAD0WcFx7K677oolS5bEtddeG08++WScdtppceGFF8aLL77Y4/iDBw/Ge97zntixY0esX78+tm7dGrfeemtMnjy5a8zDDz8cCxcujMceeyx+9rOfxauvvhp/+Zd/Gfv37+//KwMAAACAN1BS6IQbbrghLrvssrj00ksjImLNmjXxwAMPxNq1a2Pp0qWHjF+7dm3s3bs3Hn300Rg9enRERFRXV3cbs2HDhm5/v+2222L8+PHR2NgY73rXuwpdIgAAAAD0SUF3jh08eDAaGxtj9uzZrx9g1KiYPXt2NDQ09Djnvvvui/r6+li4cGFMmDAhTjnllFixYkV0dHT0ep59+/ZFRERFRUWvYw4cOBC5XK7bFwAAAAAUoqA4tmfPnujo6IgJEyZ02z5hwoRobm7ucc6zzz4b69evj46OjnjwwQfjC1/4QnzrW9+Kr371qz2O7+zsjCuvvDJmzZoVp5xySq9rWblyZZSXl3d9TZkypZCXAgAAAAAD/9sqOzs7Y/z48XHLLbdEXV1dzJs3L5YvXx5r1qzpcfzChQvj6aefjjvvvPOwx122bFns27ev6+uFF14YiOUDAAAAMIIV9Myx4447LoqLi2P37t3dtu/evTsmTpzY45yqqqoYPXp0FBcXd22bNm1aNDc3x8GDB2PMmDFd2xctWhT3339//OIXv4jjjz/+sGsZO3ZsjB07tpDlAwAAAEA3BcWxMWPGRF1dXWzcuDHmzp0bEX+8M2zjxo2xaNGiHufMmjUr7rjjjujs7IxRo/54o9q2bduiqqqqK4zl8/n4zGc+E/fcc09s2rQpTjrppD/jJQEAAACMLHv37o3W1tY+j9+1a1fXnzt37uzTnLKyssM+/32kKvi3VS5ZsiQWLFgQZ555Zpx99tmxatWq2L9/f9dvr7zkkkti8uTJsXLlyoiIuPzyy+PGG2+MxYsXx2c+85l45plnYsWKFXHFFVd0HXPhwoVxxx13xI9//OM45phjup5fVl5eHqWlpUfidQIAAAAMS3v37o3FixdHS0tLn+f86RcXXnfddZHNZvs0p7KyMlavXp1cICs4js2bNy9aWlrimmuuiebm5jj99NNjw4YNXQ/p37lzZ9cdYhERU6ZMiYceeiiuuuqqOPXUU2Py5MmxePHiuPrqq7vG3HzzzRERcf7553c71/e///342Mc+1o+XBQAAADAytLa2RktLS5SWlkYmk+nTnD/9AsNsNhslJW+cf9ra2qKlpSVaW1vFsb5YtGhRrx+j3LRp0yHb6uvr47HHHuv1ePl8vj/LAAAAAEhGJpOJsrKyPo8/9thjCzp+e3t7gSsaGQb8t1UCAAAAwFAljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFn9+m2VAADAwGtvb49cLhdFRUXxyiuvDNh52traIpfLJftbygBImzgGAABD1Pbt26OhoeGonm/q1KlH7XwAMBSIYwAAMETV1NREfX19lJeXRyaTGbDztLW1xb59+6KmpmbAzgEAQ5U4BgAAQ1RpaWlks9moqKiIsrKyATtPa2tr5PP5KC0tHbBzAMBQ5YH8AAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECySgZ7AQD0rL29PXK5XBQVFcUrr7wyIOdoa2uLXC4X7e3tA3J8AI6Mtra2Po997bXXIpfLRTabjZKSvv1zv5DjA8BII44BDFHbt2+PhoaGo3auqVOnHpVzAdB3ZWVlUVlZGS0tLX3+Dxm5XC4aGhqivr4+stlsn89VWVkZZWVl/V0qAAxb4hjAEFVTUxP19fVRXl4emUxmQM7R1tYW+/bti5qamgE5PgB/noqKili9enW0trb2ec7mzZtjzpw5sXz58pg+fXqf55WVlUVFRUV/lgkAw5o4BjBElZaWRjabjYqKigH7L/mtra2Rz+ejtLR0QI4PwJ+voqKioGi1Z8+eiIioqqqKE044YaCWBQAjhgfyAwAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBklQz2AoDCtLW1RVNT0yHbt2zZ0u3PntTW1kYmkxmwtQEAAMBwI47BMNPU1BR1dXW97p8/f36v+xobG2PGjBkDsSwAAAAYlsQxGGZqa2ujsbHxkO3t7e2xY8eOqK6ujtLS0l7nAgAAAK8Tx2CYyWQyvd79NWvWrKO8GgAAABjePJAfAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECySgZ7AQAAABxeW1tbn8e+9tprkcvlIpvNRklJ337kK+T4ACONOAYAADBElZWVRWVlZbS0tER7e3uf5uRyuWhoaIj6+vrIZrN9PldlZWWUlZX1d6kAw5Y4BgAAMERVVFTE6tWro7W1tc9zNm/eHHPmzInly5fH9OnT+zyvrKwsKioq+rNMgGFNHAMAABjCKioqCopWe/bsiYiIqqqqOOGEEwZqWQAjhgfyAwAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFklg70AAAAK09bWFk1NTT3u27JlS7c//6Pa2trIZDIDtjYAgOFGHAMAGGaampqirq7usGPmz5/f4/bGxsaYMWPGQCwLAGBY6lccu+mmm+L666+P5ubmOO200+I73/lOnH322b2Of+mll2L58uVx9913x969e+PEE0+MVatWxfve975+HxMAIFW1tbXR2NjY47729vbYsWNHVFdXR2lpaY9zAQB4XcFx7K677oolS5bEmjVrYubMmbFq1aq48MILY+vWrTF+/PhDxh88eDDe8573xPjx42P9+vUxefLkeP755+PYY4/t9zEBAFKWyWQOe/fXrFmzjuJqAACGt4IfyH/DDTfEZZddFpdeemm87W1vizVr1kQmk4m1a9f2OH7t2rWxd+/euPfee2PWrFlRXV0d5513Xpx22mn9PiYAAAAAHAkFxbGDBw9GY2NjzJ49+/UDjBoVs2fPjoaGhh7n3HfffVFfXx8LFy6MCRMmxCmnnBIrVqyIjo6Ofh8zIuLAgQORy+W6fQEAAABAIQqKY3v27ImOjo6YMGFCt+0TJkyI5ubmHuc8++yzsX79+ujo6IgHH3wwvvCFL8S3vvWt+OpXv9rvY0ZErFy5MsrLy7u+pkyZUshLAQAAAIDCP1ZZqM7Ozhg/fnzccsstUVdXF/PmzYvly5fHmjVr/qzjLlu2LPbt29f19cILLxyhFQMAAACQioIeyH/cccdFcXFx7N69u9v23bt3x8SJE3ucU1VVFaNHj47i4uKubdOmTYvm5uY4ePBgv44ZETF27NgYO3ZsIcsHAAAAgG4KunNszJgxUVdXFxs3buza1tnZGRs3boz6+voe58yaNSu2b98enZ2dXdu2bdsWVVVVMWbMmH4dEwAAAACOhII/VrlkyZK49dZb4/bbb48tW7bE5ZdfHvv3749LL700IiIuueSSWLZsWdf4yy+/PPbu3RuLFy+Obdu2xQMPPBArVqyIhQsX9vmYAAAAADAQCvpYZUTEvHnzoqWlJa655ppobm6O008/PTZs2ND1QP2dO3fGqFGvN7cpU6bEQw89FFdddVWceuqpMXny5Fi8eHFcffXVfT4mAAAAAAyEguNYRMSiRYti0aJFPe7btGnTIdvq6+vjscce6/cxAQAAAGAgDPhvqwQAAACAoapfd44BAEfH3r17o7W1tc/jd+3a1fXnzp07+zyvrKwsKioqCl4fAAAMd+IYAAxRf/qFNi0tLX2ek8vlIiLiuuuui2w22+d5lZWVsXr1aoEMAIDkiGMAMES1trZGS0tLlJaWRiaT6dOc8vLyKC8vj2w2GyUlffu/+ba2tmhpaYnW1lZxDACA5IhjADDEZTKZKCsr6/P4Y489tuBztLe3FzwHAABGAg/kBwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLJKBnsBAAAAFK6trS2ampoO2b5ly5Zuf/aktrY2MpnMgK0NYDgRxwAAAIahpqamqKur63X//Pnze93X2NgYM2bMGIhlAQw74hgAAMAwVFtbG42NjYdsb29vjx07dkR1dXWUlpb2OheAPxLHAAAAhqFMJtPr3V+zZs06yqsBGL48kB8AAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLJKBnsBAAAAAPSuvb09crlcFBUVxSuvvDIg52hra4tcLhft7e0DcvyhTBwDAAAAGMK2b98eDQ0NR+1cU6dOPSrnGirEMQAAAIAhrKamJurr66O8vDwymcyAnKOtrS327dsXNTU1A3L8oUwcAwAAABjCSktLI5vNRkVFRZSVlQ3IOVpbWyOfz0dpaemAHH8o80B+AAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJCsksFeAACH19bW1uexr732WuRyuchms1FS8sZv8YUcGwAAYCQSxwCGqLKysqisrIyWlpZob2/v05xcLhcNDQ1RX18f2Wy2T3MqKyujrKzsz1kqAADAsCWOAQxRFRUVsXr16mhtbe3znM2bN8ecOXNi+fLlMX369D7NKSsri4qKiv4uEwAAYFgTxwCGsIqKioLC1Z49eyIioqqqKk444YSBWhYAAMCI4YH8AAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSVTLYCwAAAADgjbW1tfV57GuvvRa5XC6y2WyUlLxx/ink2CONOAYAAAAwhJWVlUVlZWW0tLREe3t7n+bkcrloaGiI+vr6yGazfZpTWVkZZWVlf85ShyVxDAAAAGAIq6ioiNWrV0dra2uf52zevDnmzJkTy5cvj+nTp/dpTllZWVRUVPR3mcOWOAYAAAAwxFVUVBQUrvbs2RMREVVVVXHCCScM1LJGBA/kBwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWf2KYzfddFNUV1fHuHHjYubMmfH444/3Ova2226LoqKibl/jxo3rNqa1tTUWLVoUxx9/fJSWlsbb3va2WLNmTX+WBgAAAAB9VlLohLvuuiuWLFkSa9asiZkzZ8aqVaviwgsvjK1bt8b48eN7nJPNZmPr1q1dfy8qKuq2f8mSJfHzn/881q1bF9XV1fHTn/40Pv3pT8ekSZPir//6rwtdIgAAAAD0ScF3jt1www1x2WWXxaWXXtp1h1cmk4m1a9f2OqeoqCgmTpzY9TVhwoRu+x999NFYsGBBnH/++VFdXR2f+tSn4rTTTjvsHWkHDhyIXC7X7QsAAAAAClHQnWMHDx6MxsbGWLZsWde2UaNGxezZs6OhoaHXea2trXHiiSdGZ2dnzJgxI1asWBFvf/vbu/afc845cd9998XHP/7xmDRpUmzatCm2bdsW3/72t3s95sqVK+NLX/pSIcsHgGGlvb09crlcFBUVxSuvvDJg52lra4tcLhft7e0Ddg4AABiqCopje/bsiY6OjkPu/JowYUI0NTX1OGfq1Kmxdu3aOPXUU2Pfvn3xzW9+M84555z47W9/G8cff3xERHznO9+JT33qU3H88cdHSUlJjBo1Km699dZ417ve1etali1bFkuWLOn6ey6XiylTphTycgBgSNu+ffth/+PTQJxv6tSpR+18AAAwFBT8zLFC1dfXR319fdffzznnnJg2bVp897vfja985SsR8cc49thjj8V9990XJ554YvziF7+IhQsXxqRJk2L27Nk9Hnfs2LExduzYgV4+AAyampqaqK+vj/Ly8shkMgN2nra2tti3b1/U1NQM2DkAAGCoKiiOHXfccVFcXBy7d+/utn337t0xceLEPh1j9OjRccYZZ8T27dsj4o8fGfn85z8f99xzT1x00UUREXHqqafGU089Fd/85jd7jWMAMNKVlpZGNpuNioqKKCsrG7DztLa2Rj6fj9LS0gE7BwAADFUFPZB/zJgxUVdXFxs3buza1tnZGRs3bux2d9jhdHR0xObNm6OqqioiIl599dV49dVXY9So7kspLi6Ozs7OQpYHAAAAAAUp+GOVS5YsiQULFsSZZ54ZZ599dqxatSr2798fl156aUREXHLJJTF58uRYuXJlRER8+ctfjne84x1RU1MTL730Ulx//fXx/PPPxyc/+cmIiMhms3HeeefF5z73uSgtLY0TTzwxHn744fjf//t/xw033HAEXyoAAAAAdFdwHJs3b160tLTENddcE83NzXH66afHhg0buh7Sv3Pnzm53gf3hD3+Iyy67LJqbm+PNb35z1NXVxaOPPhpve9vbusbceeedsWzZsrj44otj7969ceKJJ8Z1110X//2///cj8BIBAAAAoGf9eiD/okWLYtGiRT3u27RpU7e/f/vb345vf/vbhz3exIkT4/vf/35/lgIAAAAA/VbQM8cAAAAAYCQRxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBklQz2AgAoTFtbWzQ1NfW4b8uWLd3+/I9qa2sjk8kM2NoAAACGG3EMYJhpamqKurq6w46ZP39+j9sbGxtjxowZA7EsAACAYUkcAxhmamtro7Gxscd97e3tsWPHjqiuro7S0tIe5wIAAPA6cQxgmMlkMoe9+2vWrFlHcTUAAADDmwfyAwAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLJKBnsBAAAAABSura0tmpqaety3ZcuWbn/+R7W1tZHJZAZsbcOJOAYAAAAwDDU1NUVdXd1hx8yfP7/H7Y2NjTFjxoyBWNawI44BAAAADEO1tbXR2NjY47729vbYsWNHVFdXR2lpaY9z+SNxDAAAAGAYymQyh737a9asWUdxNcOXB/IDAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQrJLBXgAAcHhtbW19Hvvaa69FLpeLbDYbJSV9+7/5Qo4PDB1tbW3R1NR0yPYtW7Z0+/M/qq2tjUwmM6BrA4DhRBwDgCGqrKwsKisro6WlJdrb2/s0J5fLRUNDQ9TX10c2m+3zuSorK6OsrKy/SwUGQVNTU9TV1fW6f/78+T1ub2xsjBkzZgzUsgBg2CnK5/P5wV7EkZDL5aK8vDz27dtX0A8DADCU7d27N1pbW/s8fvPmzTFnzpy4//77Y/r06X2eV1ZWFhUVFf1ZIjBIertzrL29PXbs2BHV1dVRWlp6yH53jgGQgkI6kTvHAGAIq6ioKCha7dmzJyIiqqqq4oQTThioZQFDQCaT6fUOsFmzZh3l1QDA8OWB/AAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAsvoVx2666aaorq6OcePGxcyZM+Pxxx/vdextt90WRUVF3b7GjRt3yLgtW7bEX//1X0d5eXm86U1virPOOit27tzZn+UBAAAAQJ8UHMfuuuuuWLJkSVx77bXx5JNPxmmnnRYXXnhhvPjii73OyWazsWvXrq6v559/vtv+f//3f493vvOdUVtbG5s2bYp//dd/jS984Qs9RjQAAAAAOFJKCp1www03xGWXXRaXXnppRESsWbMmHnjggVi7dm0sXbq0xzlFRUUxceLEXo+5fPnyeN/73hff+MY3urb9xV/8RaFLAwAAAICCFHTn2MGDB6OxsTFmz579+gFGjYrZs2dHQ0NDr/NaW1vjxBNPjClTpsT73//++O1vf9u1r7OzMx544IE4+eST48ILL4zx48fHzJkz49577z3sWg4cOBC5XK7bFwAAAAAUoqA4tmfPnujo6IgJEyZ02z5hwoRobm7ucc7UqVNj7dq18eMf/zjWrVsXnZ2dcc4558T/+3//LyIiXnzxxWhtbY2vfe1r8V/+y3+Jn/70p/GBD3wgPvjBD8bDDz/c61pWrlwZ5eXlXV9Tpkwp5KUAAAAAQOEfqyxUfX191NfXd/39nHPOiWnTpsV3v/vd+MpXvhKdnZ0REfH+978/rrrqqoiIOP300+PRRx+NNWvWxHnnndfjcZctWxZLlizp+nsulxPIAAAAAChIQXHsuOOOi+Li4ti9e3e37bt37z7sM8X+/0aPHh1nnHFGbN++veuYJSUl8ba3va3buGnTpsUvf/nLXo8zduzYGDt2bCHLBwAAAIBuCvpY5ZgxY6Kuri42btzYta2zszM2btzY7e6ww+no6IjNmzdHVVVV1zHPOuus2Lp1a7dx27ZtixNPPLGQ5QEAAABAQQr+WOWSJUtiwYIFceaZZ8bZZ58dq1ativ3793f99spLLrkkJk+eHCtXroyIiC9/+cvxjne8I2pqauKll16K66+/Pp5//vn45Cc/2XXMz33uczFv3rx417veFRdccEFs2LAh/umf/ik2bdp0ZF4lAAAAAPSg4Dg2b968aGlpiWuuuSaam5vj9NNPjw0bNnQ9pH/nzp0xatTrN6T94Q9/iMsuuyyam5vjzW9+c9TV1cWjjz7a7WOUH/jAB2LNmjWxcuXKuOKKK2Lq1Knxox/9KN75zncegZcIAAAAAD0ryufz+cFexJGQy+WivLw89u3bF9lsdrCXAwCD4sknn4y6urpobGyMGTNmDPZyAABgUBTSiQp65hgAAAAAjCTiGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGSVDPYCAIDCtLW1RVNTU4/7tmzZ0u3P/6i2tjYymcyArQ0AAIYbcQwAhpmmpqaoq6s77Jj58+f3uL2xsTFmzJgxEMsCAIBhSRwDgGGmtrY2Ghsbe9zX3t4eO3bsiOrq6igtLe1xLgAA8LqifD6fH+xFHAm5XC7Ky8tj3759kc1mB3s5AAAAAAySQjqRB/IDAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEscAAAAASJY4BgAAAECyxDEAAAAAkiWOAQAAAJAscQwAAACAZIljAAAAACRLHAMAAAAgWeIYAAAAAMkSxwAAAABIljgGAAAAQLLEMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAskoGewFHSj6fj4iIXC43yCsBAAAAYDD9qQ/9qRcdzoiJYy+//HJEREyZMmWQVwIAAADAUPDyyy9HeXn5YccU5fuS0IaBzs7O+P3vfx/HHHNMFBUVDfZyjrpcLhdTpkyJF154IbLZ7GAvh0HgGiDCdYBrANcArgFcA7gG+KPUr4N8Ph8vv/xyTJo0KUaNOvxTxUbMnWOjRo2K448/frCXMeiy2WySFz2vcw0Q4TrANYBrANcArgFcA/xRytfBG90x9iceyA8AAABAssQxAAAAAJIljo0QY8eOjWuvvTbGjh072EthkLgGiHAd4BrANYBrANcArgH+yHXQdyPmgfwAAAAAUCh3jgEAAACQLHEMAAAAgGSJYwAAAAAkSxwDAAAAIFniGAAAAADJEseGkZtuuimqq6tj3LhxMXPmzHj88ccPO/4f//Efo7a2NsaNGxfTp0+PBx988CitlIHwi1/8Iv7qr/4qJk2aFEVFRXHvvfe+4ZxNmzbFjBkzYuzYsVFTUxO33XbbgK+TgbNy5co466yz4phjjonx48fH3LlzY+vWrW84z3vByHHzzTfHqaeeGtlsNrLZbNTX18dPfvKTw87x/R/Zvva1r0VRUVFceeWVhx3nOhg5vvjFL0ZRUVG3r9ra2sPO8f0feX73u9/F/Pnz4y1veUuUlpbG9OnT49e//vVh5/h34chSXV19yHtBUVFRLFy4sNc53gtGlo6OjvjCF74QJ510UpSWlsZf/MVfxFe+8pXI5/OHnee9oGfi2DBx1113xZIlS+Laa6+NJ598Mk477bS48MIL48UXX+xx/KOPPhp/8zd/E5/4xCfiN7/5TcydOzfmzp0bTz/99FFeOUfK/v3747TTToubbrqpT+Ofe+65uOiii+KCCy6Ip556Kq688sr45Cc/GQ899NAAr5SB8vDDD8fChQvjsccei5/97Gfx6quvxl/+5V/G/v37e53jvWBkOf744+NrX/taNDY2xq9//ev4z//5P8f73//++O1vf9vjeN//ke2JJ56I7373u3HqqacedpzrYOR5+9vfHrt27er6+uUvf9nrWN//kecPf/hDzJo1K0aPHh0/+clP4t/+7d/iW9/6Vrz5zW/udY5/F448TzzxRLf3gZ/97GcREfHhD3+4x/HeC0aer3/963HzzTfHjTfeGFu2bImvf/3r8Y1vfCO+853v9DrHe0HvivJvlBUZEmbOnBlnnXVW3HjjjRER0dnZGVOmTInPfOYzsXTp0kPGz5s3L/bv3x/3339/17Z3vOMdcfrpp8eaNWuO2roZGEVFRXHPPffE3Llzex1z9dVXxwMPPNDt//A+8pGPxEsvvRQbNmw4CqtkoLW0tMT48ePj4Ycfjne96109jvFeMPJVVFTE9ddfH5/4xCcO2ef7P3K1trbGjBkz4n/9r/8VX/3qV+P000+PVatW9TjWdTCyfPGLX4x77703nnrqqT6N9/0feZYuXRq/+tWv4pFHHunzHP8uHPmuvPLKuP/+++OZZ56JoqKiQ/Z7Lxh55syZExMmTIjvfe97Xdv+63/9r1FaWhrr1q3rcY73gt65c2wYOHjwYDQ2Nsbs2bO7to0aNSpmz54dDQ0NPc5paGjoNj4i4sILL+x1PCOPa2Dk27dvX0T8MY70xnUwcnV0dMSdd94Z+/fvj/r6+h7H+P6PXAsXLoyLLrrokO9vT1wHI88zzzwTkyZNire+9a1x8cUXx86dO3sd6/s/8tx3331x5plnxoc//OEYP358nHHGGXHrrbcedo7rYGQ7ePBgrFu3Lj7+8Y/3GMYiXAMj0TnnnBMbN26Mbdu2RUTEv/zLv8Qvf/nLeO9739vrHNdB70oGewG8sT179kRHR0dMmDCh2/YJEyZEU1NTj3Oam5t7HN/c3Dxg62Ro6e0ayOVy0d7eHqWlpYO0Mo6Ezs7OuPLKK2PWrFlxyimn9DrOe8HIs3nz5qivr49XXnklysrK4p577om3ve1tPY71/R+Z7rzzznjyySfjiSee6NN418HIMnPmzLjtttti6tSpsWvXrvjSl74U5557bjz99NNxzDHHHDLe93/kefbZZ+Pmm2+OJUuWxOc///l44okn4oorrogxY8bEggULepzj34Uj27333hsvvfRSfOxjH+t1jPeCkWfp0qWRy+WitrY2iouLo6OjI6677rq4+OKLe53jvaB34hjAMLRw4cJ4+umnD/ucGUamqVOnxlNPPRX79u2L9evXx4IFC+Lhhx/uNZAxsrzwwguxePHi+NnPfhbjxo0b7OUwCP7/dwSceuqpMXPmzDjxxBPjhz/8YY8fr2bk6ezsjDPPPDNWrFgRERFnnHFGPP3007FmzZpe4xgj2/e+971473vfG5MmTRrspXAU/fCHP4wf/OAHcccdd8Tb3/72rmeITZo0yXtBP4hjw8Bxxx0XxcXFsXv37m7bd+/eHRMnTuxxzsSJEwsaz8jT2zWQzWaT/i8CI8GiRYvi/vvvj1/84hdx/PHHH3as94KRZ8yYMVFTUxMREXV1dfHEE0/E6tWr47vf/e4hY33/R57GxsZ48cUXY8aMGV3bOjo64he/+EXceOONceDAgSguLu42x3Uwsh177LFx8sknx/bt23vc7/s/8lRVVR3yH0SmTZsWP/rRj3qd49+FI9fzzz8f/+f//J+4++67DzvOe8HI87nPfS6WLl0aH/nIRyIiYvr06fH888/HypUre41j3gt655ljw8CYMWOirq4uNm7c2LWts7MzNm7c2OtzZurr67uNj4j42c9+1ut4Rh7XwMiTz+dj0aJFcc8998TPf/7zOOmkk95wjutg5Ovs7IwDBw70uM/3f+R597vfHZs3b46nnnqq6+vMM8+Miy++OJ566qlDwliE62Cka21tjX//93+PqqqqHvf7/o88s2bNiq1bt3bbtm3btjjxxBN7neM6GLm+//3vx/jx4+Oiiy467DjXwMjT1tYWo0Z1TzrFxcXR2dnZ6xzXwWHkGRbuvPPO/NixY/O33XZb/t/+7d/yn/rUp/LHHntsvrm5OZ/P5/N/+7d/m1+6dGnX+F/96lf5kpKS/De/+c38li1b8tdee21+9OjR+c2bNw/WS+DP9PLLL+d/85vf5H/zm9/kIyJ/ww035H/zm9/kn3/++Xw+n88vXbo0/7d/+7dd45999tl8JpPJf+5zn8tv2bIlf9NNN+WLi4vzGzZsGKyXwJ/p8ssvz5eXl+c3bdqU37VrV9dXW1tb1xjvBSPb0qVL8w8//HD+ueeey//rv/5rfunSpfmioqL8T3/603w+7/ufqvPOOy+/ePHirr+7Dka2z372s/lNmzbln3vuufyvfvWr/OzZs/PHHXdc/sUXX8zn877/KXj88cfzJSUl+euuuy7/zDPP5H/wgx/kM5lMft26dV1j/LswDR0dHfkTTjghf/XVVx+yz3vByLdgwYL85MmT8/fff3/+ueeey99999354447Lv/3f//3XWO8F/SdODaMfOc738mfcMIJ+TFjxuTPPvvs/GOPPda177zzzssvWLCg2/gf/vCH+ZNPPjk/ZsyY/Nvf/vb8Aw88cJRXzJH0f//v/81HxCFff/q+L1iwIH/eeecdMuf000/PjxkzJv/Wt741//3vf/+or5sjp6fvf0R0+756LxjZPv7xj+dPPPHE/JgxY/KVlZX5d7/73V1hLJ/3/U/Vf4xjroORbd68efmqqqr8mDFj8pMnT87Pmzcvv3379q79vv9p+Kd/+qf8Kaeckh87dmy+trY2f8stt3Tb79+FaXjooYfyEZHfunXrIfu8F4x8uVwuv3jx4vwJJ5yQHzduXP6tb31rfvny5fkDBw50jfFe0HdF+Xw+Pyi3rAEAAADAIPPMMQAAAACSJY4BAAAAkCxxDAAAAIBkiWMAAAAAJEscAwAAACBZ4hgAAAAAyRLHAAAAAEiWOAYAAABAssQxAAAAAJIljgEAAACQLHEMAAAAgGT9f9FNLu9fIqa7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Define the openai API key (Make sure to keep it confidential!)\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Utility functions\n",
    "def get_matching_cols(df, regex):\n",
    "    r = re.compile(regex)\n",
    "    return list(filter(r.match, df.columns))\n",
    "\n",
    "def get_embedding_cols(df):\n",
    "    return get_matching_cols(df, \"(vec_\\d+)\")\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return openai.Embedding.create(input=[text], model=model)['data'][0]['embedding']\n",
    "\n",
    "def explode(col, prefix):\n",
    "    n_cols = len(col[0])\n",
    "    col_names = [prefix + str(i) for i in range(n_cols)]\n",
    "    return pd.DataFrame(col.to_list(), columns=col_names)\n",
    "\n",
    "# Methods for feature engineering\n",
    "def method_baseline(df):\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    y = df['Outcome']\n",
    "    X_cat = X[['Age', 'Sex', 'Height', 'Weight', 'Pregnancy status', 'Murmur', 'Most audible location', 'Systolic murmur timing', 'Systolic murmur shape', 'Systolic murmur grading', 'Systolic murmur pitch', 'Systolic murmur quality', 'Diastolic murmur timing', 'Diastolic murmur shape', 'Diastolic murmur grading', 'Diastolic murmur pitch', 'Diastolic murmur quality', 'Campaign', 'PV', 'TV', 'AV', 'MV']]\n",
    "    scaler = StandardScaler()\n",
    "    X_final = scaler.fit_transform(X_cat)\n",
    "    return X_final, y\n",
    "\n",
    "column = pd.read_csv('/data/chenxi/3/3/sum.csv')\n",
    "column = column.reset_index(drop=True)\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "df_clean['sum'] = column['sum']\n",
    "\n",
    "# Getting embeddings for the 'sum' column\n",
    "df_clean['text_vector'] = generator.generate_embeddings(text_col=df_clean['sum'])\n",
    "print(df_clean.head())\n",
    "\n",
    "\n",
    "def method_SelectK(df):\n",
    "        \n",
    "    def explode( col, prefix ):\n",
    "        n_cols = len( col[0] )\n",
    "        col_names = [ prefix + str(i) for i in range(n_cols) ]\n",
    "\n",
    "        return( pd.DataFrame( col.to_list(), columns=col_names) )\n",
    "\n",
    "    tab_vec_name = 'text_vector'\n",
    "    prefix = \"vec_\" \n",
    "\n",
    "    # train_X\n",
    "    exploded = explode( df[ tab_vec_name], prefix )\n",
    "    df.loc[:, exploded.columns ] = exploded   # Idempotent replacement\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    y = df['Outcome']\n",
    "\n",
    "    # Separate original categorical features\n",
    "    X_cat = X[['Age', 'Sex', 'Height', 'Weight', 'Pregnancy status', 'Murmur', 'Most audible location', 'Systolic murmur timing', 'Systolic murmur shape', 'Systolic murmur grading', 'Systolic murmur pitch', 'Systolic murmur quality', 'Diastolic murmur timing', 'Diastolic murmur shape', 'Diastolic murmur grading', 'Diastolic murmur pitch', 'Diastolic murmur quality', 'Campaign', 'PV', 'TV', 'AV', 'MV']]\n",
    "    \n",
    "    # Extract the text embeddings\n",
    "    embed_cols = get_embedding_cols(X)\n",
    "    X_text = X[embed_cols]\n",
    "\n",
    "    # Combine the embeddings and the original set\n",
    "    X_comb = pd.concat([X_cat, X_text], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_comb)\n",
    "        # Initialize multiple feature selection methods\n",
    "    feature_selection_methods = {\n",
    "        'SelectKBest': SelectKBest(mutual_info_classif, k=20),\n",
    "    }\n",
    "\n",
    "    # Initialize an empty dictionary to store the selected features from each method\n",
    "    selected_features = {}\n",
    "\n",
    "    # Apply each feature selection method to the embeddings\n",
    "    for name, method in feature_selection_methods.items():\n",
    "        selected_features[name] = method.fit_transform(X_scaled, y)\n",
    "\n",
    "    # Train a model (for example, logistic regression) on the selected features and compute the performance\n",
    "    model = LogisticRegression(max_iter=1000000)\n",
    "    scores = {}\n",
    "    for name, features in selected_features.items():\n",
    "        score = cross_val_score(model, features, y, cv=5, scoring='roc_auc').mean()\n",
    "        scores[name] = score\n",
    "\n",
    "    # Determine the best feature selection method\n",
    "    best_method = max(scores, key=scores.get)\n",
    "\n",
    "    # Use the selected features from the best method for further analysis\n",
    "    X_selected = selected_features[best_method]\n",
    "    \n",
    "    X_final = pd.concat([X_cat, pd.DataFrame(X_selected)], axis=1)\n",
    "    X_final.columns = X_final.columns.astype(str)\n",
    "    return X_final, y\n",
    "\n",
    "\n",
    "def method_PCA(df):\n",
    "\n",
    "    # Exploding the embeddings into separate columns\n",
    "    exploded = explode(df['text_vector'], 'vec_')\n",
    "    df.loc[:, exploded.columns] = exploded\n",
    "    \n",
    "    # Splitting X and y\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    y = df['Outcome']\n",
    "\n",
    "    # Separate original categorical features\n",
    "    X_cat = X[['Age', 'Sex', 'Height', 'Weight', 'Pregnancy status', 'Murmur', 'Most audible location', 'Systolic murmur timing', 'Systolic murmur shape', 'Systolic murmur grading', 'Systolic murmur pitch', 'Systolic murmur quality', 'Diastolic murmur timing', 'Diastolic murmur shape', 'Diastolic murmur grading', 'Diastolic murmur pitch', 'Diastolic murmur quality', 'Campaign', 'PV', 'TV', 'AV', 'MV']]\n",
    "    \n",
    "    # Extract the text embeddings\n",
    "    embed_cols = get_embedding_cols(X)\n",
    "    X_text = X[embed_cols]\n",
    "\n",
    "    # Combine the embeddings and the original set\n",
    "    X_comb = pd.concat([X_cat, X_text], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_comb)\n",
    "\n",
    "    # Applying PCA on the combined data\n",
    "    best_n_components = None\n",
    "    best_score = float('-inf')\n",
    "    for n_components in range(1, 50):  # Checking all possible number of components\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "        # Train a model (e.g., logistic regression) on the PCA components and compute the performance\n",
    "        model = LogisticRegression()\n",
    "        score = cross_val_score(model, X_pca, y, cv=5, scoring='roc_auc').mean()\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_n_components = n_components\n",
    "\n",
    "    # Use PCA with the best number of components\n",
    "    pca = PCA(n_components=best_n_components)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Combining PCA components with original categorical data\n",
    "    X_final = pd.DataFrame(X_pca)\n",
    "    X_final.columns = X_final.columns.astype(str)\n",
    "\n",
    "    return X_final, y\n",
    "\n",
    "\n",
    "# Main evaluation function\n",
    "def evaluate_models(df, models, methods):\n",
    "    # logic to evaluate models with provided methods\n",
    "    colors = ['black', 'green', 'blue', 'red']\n",
    "\n",
    "    for metric in ['accuracy', 'roc_auc']:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "\n",
    "        # Iterate through methods\n",
    "        for i, method in enumerate(methods):\n",
    "            if method == 'baseline':\n",
    "                X_final, y = method_baseline(df)\n",
    "            elif method == 'PCA':\n",
    "                X_final, y = method_PCA(df)\n",
    "            elif method == 'SelectK':\n",
    "                X_final, y = method_SelectK(df)\n",
    "        \n",
    "            # ... (rest of the evaluation function logic)\n",
    "            kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            performance_metrics = {metric: {model_name: cross_val_score(model, X_final, y, cv=kfold, scoring=metric) for model_name, model in models.items()}}\n",
    "\n",
    "            for name, scores in performance_metrics[metric].items():\n",
    "                print(f'{name}: {metric}: {scores.mean()} ± {scores.std()}')\n",
    "\n",
    "            x_ticks_positions = np.arange(len(models)) + i * 0.2\n",
    "            plt.boxplot([performance_metrics[metric][model_name] for model_name in models.keys()], positions=x_ticks_positions, widths=0.2, patch_artist=True,\n",
    "                        boxprops=dict(facecolor=colors[i], color=colors[i], alpha=0.6),\n",
    "                        capprops=dict(color=colors[i]),\n",
    "                        whiskerprops=dict(color=colors[i]),\n",
    "                        flierprops=dict(color=colors[i], markeredgecolor=colors[i]),\n",
    "                        medianprops=dict(color='black'))\n",
    "\n",
    "        plt.legend(handles=[mpatches.Patch(color=colors[i], label=methods[i]) for i in range(len(methods))], loc='upper right')\n",
    "        plt.title(f\"Model performance ({metric})\")\n",
    "        plt.ylabel(metric)\n",
    "        plt.xticks(ticks=np.arange(len(models)), labels=models.keys())\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "methods = ['baseline', 'SelectK', 'PCA']\n",
    "evaluate_models(df_clean, models, methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:base:Generating embedding vectors\n",
      "Map: 100%|██████████| 753/753 [00:02<00:00, 293.12 examples/s]\n",
      "INFO:base:Generating embedding vectors\n",
      "Map: 100%|██████████| 95/95 [00:00<00:00, 282.89 examples/s]\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: baseline | Model: Logistic Regression | accuracy: 0.631578947368421\n",
      "Method: baseline | Model: K-Nearest Neighbors | accuracy: 0.6210526315789474\n",
      "Method: baseline | Model: Naive Bayes | accuracy: 0.5052631578947369\n",
      "Method: baseline | Model: Decision Tree | accuracy: 0.6421052631578947\n",
      "Method: baseline | Model: Random Forest | accuracy: 0.6947368421052632\n",
      "Method: baseline | Model: AdaBoost | accuracy: 0.6842105263157895\n",
      "Method: baseline | Model: Gradient Boosting | accuracy: 0.6842105263157895\n",
      "Method: baseline | Model: Support Vector Machine | accuracy: 0.6842105263157895\n",
      "Method: baseline | Model: XGBoost | accuracy: 0.6105263157894737\n",
      "Method: SelectK | Model: Logistic Regression | accuracy: 0.631578947368421\n",
      "Method: SelectK | Model: K-Nearest Neighbors | accuracy: 0.6105263157894737\n",
      "Method: SelectK | Model: Naive Bayes | accuracy: 0.6210526315789474\n",
      "Method: SelectK | Model: Decision Tree | accuracy: 0.4842105263157895\n",
      "Method: SelectK | Model: Random Forest | accuracy: 0.7157894736842105\n",
      "Method: SelectK | Model: AdaBoost | accuracy: 0.6105263157894737\n",
      "Method: SelectK | Model: Gradient Boosting | accuracy: 0.6421052631578947\n",
      "Method: SelectK | Model: Support Vector Machine | accuracy: 0.5894736842105263\n",
      "Method: SelectK | Model: XGBoost | accuracy: 0.5894736842105263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- 10\n",
      "- 11\n",
      "- 12\n",
      "- 13\n",
      "- 14\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 6 features, but LogisticRegression is expecting 17 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 220\u001b[0m\n\u001b[1;32m    208\u001b[0m models \u001b[39m=\u001b[39m {\n\u001b[1;32m    209\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mLogistic Regression\u001b[39m\u001b[39m'\u001b[39m: LogisticRegression(max_iter\u001b[39m=\u001b[39m\u001b[39m100000000\u001b[39m),\n\u001b[1;32m    210\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mK-Nearest Neighbors\u001b[39m\u001b[39m'\u001b[39m: KNeighborsClassifier(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mXGBoost\u001b[39m\u001b[39m'\u001b[39m: XGBClassifier(use_label_encoder\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, eval_metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlogloss\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m    218\u001b[0m }\n\u001b[1;32m    219\u001b[0m methods \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mbaseline\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSelectK\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPCA\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 220\u001b[0m evaluate_models(train_data, test_data, models, methods)\n",
      "Cell \u001b[0;32mIn[9], line 175\u001b[0m, in \u001b[0;36mevaluate_models\u001b[0;34m(train_df, test_df, models, methods)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mfor\u001b[39;00m model_name, model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    174\u001b[0m     model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m--> 175\u001b[0m     y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m    177\u001b[0m     \u001b[39m# Compute metrics\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[39mif\u001b[39;00m metric \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:425\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    412\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[39m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m    426\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    427\u001b[0m         indices \u001b[39m=\u001b[39m (scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:407\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39mPredict confidence scores for samples.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[39m    this class would be predicted.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 407\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    408\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m    409\u001b[0m \u001b[39mreturn\u001b[39;00m scores\u001b[39m.\u001b[39mravel() \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    587\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/data/chenxi/anaconda3/envs/myenv/lib/python3.10/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 6 features, but LogisticRegression is expecting 17 features as input."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "# Define the openai API key (Make sure to keep it confidential!)\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Utility functions\n",
    "def get_matching_cols(df, regex):\n",
    "    r = re.compile(regex)\n",
    "    return list(filter(r.match, df.columns))\n",
    "\n",
    "def get_embedding_cols(df):\n",
    "    return get_matching_cols(df, \"(vec_\\d+)\")\n",
    "\n",
    "def explode(col, prefix):\n",
    "    n_cols = len(col[0])\n",
    "    col_names = [prefix + str(i) for i in range(n_cols)]\n",
    "    return pd.DataFrame(col.to_list(), columns=col_names)\n",
    "\n",
    "# Methods for feature engineering\n",
    "def method_baseline(df):\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    y = df['Outcome']\n",
    "    X_cat = X[['Age', 'Sex', 'Height', 'Weight', 'Pregnancy status', 'Murmur', 'Most audible location', 'Systolic murmur timing', 'Systolic murmur shape', 'Systolic murmur grading', 'Systolic murmur pitch', 'Systolic murmur quality', 'Diastolic murmur timing', 'Diastolic murmur shape', 'Diastolic murmur grading', 'Diastolic murmur pitch', 'Diastolic murmur quality', 'Campaign', 'PV', 'TV', 'AV', 'MV']]\n",
    "    scaler = StandardScaler()\n",
    "    X_final = scaler.fit_transform(X_cat)\n",
    "    return X_final, y\n",
    "train_data = pd.read_csv('/data/chenxi/3/3/train.csv') # Replace with your training dataset path\n",
    "test_data = pd.read_csv('/data/chenxi/3/3/test.csv')\n",
    "train_data['text_vector'] = generator.generate_embeddings(text_col=train_data['response'])\n",
    "test_data['text_vector'] = generator.generate_embeddings(text_col=test_data['response'])\n",
    "\n",
    "\n",
    "def method_SelectK(df):\n",
    "        \n",
    "    def explode( col, prefix ):\n",
    "        n_cols = len( col[0] )\n",
    "        col_names = [ prefix + str(i) for i in range(n_cols) ]\n",
    "\n",
    "        return( pd.DataFrame( col.to_list(), columns=col_names) )\n",
    "\n",
    "    tab_vec_name = 'text_vector'\n",
    "    prefix = \"vec_\" \n",
    "\n",
    "    # train_X\n",
    "    exploded = explode( df[ tab_vec_name], prefix )\n",
    "    df.loc[:, exploded.columns ] = exploded   # Idempotent replacement\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    y = df['Outcome']\n",
    "\n",
    "    # Separate original categorical features\n",
    "    X_cat = X[['Age', 'Sex', 'Height', 'Weight', 'Pregnancy status', 'Murmur', 'Most audible location', 'Systolic murmur timing', 'Systolic murmur shape', 'Systolic murmur grading', 'Systolic murmur pitch', 'Systolic murmur quality', 'Diastolic murmur timing', 'Diastolic murmur shape', 'Diastolic murmur grading', 'Diastolic murmur pitch', 'Diastolic murmur quality', 'Campaign', 'PV', 'TV', 'AV', 'MV']]\n",
    "    \n",
    "    # Extract the text embeddings\n",
    "    embed_cols = get_embedding_cols(X)\n",
    "    X_text = X[embed_cols]\n",
    "\n",
    "    # Combine the embeddings and the original set\n",
    "    X_comb = pd.concat([X_cat, X_text], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_comb)\n",
    "        # Initialize multiple feature selection methods\n",
    "    feature_selection_methods = {\n",
    "        'SelectKBest': SelectKBest(mutual_info_classif, k=20),\n",
    "    }\n",
    "\n",
    "    # Initialize an empty dictionary to store the selected features from each method\n",
    "    selected_features = {}\n",
    "\n",
    "    # Apply each feature selection method to the embeddings\n",
    "    for name, method in feature_selection_methods.items():\n",
    "        selected_features[name] = method.fit_transform(X_scaled, y)\n",
    "\n",
    "    # Train a model (for example, logistic regression) on the selected features and compute the performance\n",
    "    model = LogisticRegression(max_iter=1000000)\n",
    "    scores = {}\n",
    "    for name, features in selected_features.items():\n",
    "        score = cross_val_score(model, features, y, cv=5, scoring='roc_auc').mean()\n",
    "        scores[name] = score\n",
    "\n",
    "    # Determine the best feature selection method\n",
    "    best_method = max(scores, key=scores.get)\n",
    "\n",
    "    # Use the selected features from the best method for further analysis\n",
    "    X_selected = selected_features[best_method]\n",
    "    \n",
    "    X_final = pd.concat([X_cat, pd.DataFrame(X_selected)], axis=1)\n",
    "    X_final.columns = X_final.columns.astype(str)\n",
    "    return X_final, y\n",
    "\n",
    "\n",
    "def method_PCA(df):\n",
    "\n",
    "    # Exploding the embeddings into separate columns\n",
    "    exploded = explode(df['text_vector'], 'vec_')\n",
    "    df.loc[:, exploded.columns] = exploded\n",
    "    \n",
    "    # Splitting X and y\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    y = df['Outcome']\n",
    "\n",
    "    # Separate original categorical features\n",
    "    X_cat = X[['Age', 'Sex', 'Height', 'Weight', 'Pregnancy status', 'Murmur', 'Most audible location', 'Systolic murmur timing', 'Systolic murmur shape', 'Systolic murmur grading', 'Systolic murmur pitch', 'Systolic murmur quality', 'Diastolic murmur timing', 'Diastolic murmur shape', 'Diastolic murmur grading', 'Diastolic murmur pitch', 'Diastolic murmur quality', 'Campaign', 'PV', 'TV', 'AV', 'MV']]\n",
    "    \n",
    "    # Extract the text embeddings\n",
    "    embed_cols = get_embedding_cols(X)\n",
    "    X_text = X[embed_cols]\n",
    "\n",
    "    # Combine the embeddings and the original set\n",
    "    X_comb = pd.concat([X_cat, X_text], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_comb)\n",
    "\n",
    "    # Applying PCA on the combined data\n",
    "    best_n_components = None\n",
    "    best_score = float('-inf')\n",
    "    for n_components in range(1, 50):  # Checking all possible number of components\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "        # Train a model (e.g., logistic regression) on the PCA components and compute the performance\n",
    "        model = LogisticRegression()\n",
    "        score = cross_val_score(model, X_pca, y, cv=5, scoring='roc_auc').mean()\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_n_components = n_components\n",
    "\n",
    "    # Use PCA with the best number of components\n",
    "    pca = PCA(n_components=best_n_components)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Combining PCA components with original categorical data\n",
    "    X_final = pd.DataFrame(X_pca)\n",
    "    X_final.columns = X_final.columns.astype(str)\n",
    "\n",
    "    return X_final, y\n",
    "\n",
    "\n",
    "def evaluate_models(train_df, test_df, models, methods):\n",
    "    colors = ['yellow', 'red', 'blue', 'red', 'cyan', 'magenta', 'yellow']  # Added more colors for potential expansion\n",
    "    metrics_list = ['accuracy', 'roc_auc']\n",
    "\n",
    "    for metric in metrics_list:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "\n",
    "        method_results = {}  # Storing performance metrics for each method\n",
    "\n",
    "        # Iterate through methods\n",
    "        for i, method in enumerate(methods):\n",
    "            method_results[method] = {}\n",
    "\n",
    "            if method == 'baseline':\n",
    "                X_train, y_train = method_baseline(train_df)\n",
    "                X_test, y_test = method_baseline(test_df)\n",
    "            elif method == 'PCA':\n",
    "                X_train, y_train = method_PCA(train_df)\n",
    "                X_test, y_test = method_PCA(test_df)\n",
    "            elif method == 'SelectK':\n",
    "                X_train, y_train = method_SelectK(train_df)\n",
    "                X_test, y_test = method_SelectK(test_df)\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                # Compute metrics\n",
    "                if metric == 'accuracy':\n",
    "                    score = accuracy_score(y_test, y_pred)\n",
    "                elif metric == 'roc_auc':\n",
    "                    y_prob = model.predict_proba(X_test)[:, 1]  # assuming binary classification\n",
    "                    score = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "                method_results[method][model_name] = score  # Store results for this method\n",
    "\n",
    "                print(f'Method: {method} | Model: {model_name} | {metric}: {score}')\n",
    "\n",
    "        # Plot results\n",
    "        x_ticks_positions = np.arange(len(models))\n",
    "        for i, method in enumerate(methods):\n",
    "            scores_for_method = [method_results[method][model_name] for model_name in models.keys()]\n",
    "            plt.boxplot([[score] for score in scores_for_method],\n",
    "                        positions=x_ticks_positions + i * 0.2,\n",
    "                        widths=0.6,\n",
    "                        patch_artist=True,\n",
    "                        boxprops=dict(facecolor=colors[i], color=colors[i], alpha=0.6, linewidth=1.5),  # Adjusted linewidth\n",
    "                        capprops=dict(color=colors[i], linewidth=1.5),\n",
    "                        whiskerprops=dict(color=colors[i], linewidth=1.5),\n",
    "                        flierprops=dict(color=colors[i], markeredgecolor=colors[i], markersize=7),  # Adjusted markersize\n",
    "                        medianprops=dict(color='black', linewidth=1.5))\n",
    "\n",
    "        plt.xticks(ticks=x_ticks_positions + 0.3, labels=models.keys())  # center the ticks\n",
    "        plt.legend(handles=[mpatches.Patch(color=colors[i], label=method) for i, method in enumerate(methods)], loc='upper right')\n",
    "        plt.title(f\"Model performance ({metric})\")\n",
    "        plt.ylabel(metric)\n",
    "        plt.show()\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=100000000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Support Vector Machine': SVC(probability=True),  # Enable probability estimates\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "}\n",
    "methods = ['baseline', 'SelectK', 'PCA']\n",
    "evaluate_models(train_data, test_data, models, methods)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
